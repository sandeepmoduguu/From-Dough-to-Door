{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7b31006-f779-4585-9505-865ca27b5c66",
      "metadata": {
        "id": "e7b31006-f779-4585-9505-865ca27b5c66"
      },
      "source": [
        "**Rudi's Bakery Route Optimization: An Integrated Approach using Machine Learning and Optimization Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea05ed6-d8f3-466a-ac23-9810c7c8a6b1",
      "metadata": {
        "id": "6ea05ed6-d8f3-466a-ac23-9810c7c8a6b1"
      },
      "source": [
        "**Part I: Geocoding Store Delivery Locations and Generating Distance/Duration Matrices**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b397ce22-2c65-4545-8a25-77bc50ca3d71",
      "metadata": {
        "id": "b397ce22-2c65-4545-8a25-77bc50ca3d71"
      },
      "source": [
        "**Setting Up the Necessary Python Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d33513e-a0be-4ff6-b35b-3ad8da4bb3b9",
      "metadata": {
        "tags": [],
        "id": "5d33513e-a0be-4ff6-b35b-3ad8da4bb3b9"
      },
      "outputs": [],
      "source": [
        "# This Script installs and imports the necessary libraries required for the optimization and data manipulation tasks in\n",
        "# this notebook.\n",
        "\n",
        "# `gurobipy`: A Python library for mathematical optimization using the Gurobi Optimizer.\n",
        "# `pandas`: A library for data manipulation and analysis.\n",
        "# `numpy`: A library for numerical computations.\n",
        "# `requests`: A library for making HTTP requests in Python.\n",
        "# `googlemaps`: A library for interacting with Google Maps API.\n",
        "\n",
        "# Each one makes our data analysis and problem-solving tasks easier and more powerful\n",
        "\n",
        "!pip install gurobipy\n",
        "import gurobipy as gp\n",
        "\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "!pip install numpy\n",
        "import numpy as np\n",
        "\n",
        "!pip install requests\n",
        "import requests\n",
        "\n",
        "!pip install googlemaps\n",
        "import googlemaps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "707469e8-c403-4483-818f-e7aa6158e0d2",
      "metadata": {
        "id": "707469e8-c403-4483-818f-e7aa6158e0d2"
      },
      "source": [
        "**Geocoding Store Addresses and Extracting Coordinates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6f07fb-e87b-4fc4-9d05-8beffe383afb",
      "metadata": {
        "tags": [],
        "id": "9a6f07fb-e87b-4fc4-9d05-8beffe383afb"
      },
      "outputs": [],
      "source": [
        "# This script retrieves the latitude and longitude for a list of addresses from a CSV file using the Google Maps Geocoding API.\n",
        "# It's designed to help organize delivery routes by converting physical addresses into geographical coordinates.\n",
        "\n",
        "# Function to get the latitude and longitude coordinates for a given address using the Google Maps Geocoding API.\n",
        "# param address: The address to geocode.\n",
        "# param api_key: The API key for Google Maps services.\n",
        "# return: A tuple of (latitude, longitude) if successful, None otherwise.\n",
        "\n",
        "def get_geocode(address, api_key):\n",
        "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
        "    params = {\n",
        "        \"address\": address,\n",
        "        \"key\": api_key\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        if result[\"status\"] == \"OK\":\n",
        "            latitude = result[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
        "            longitude = result[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
        "            return latitude, longitude\n",
        "    return None\n",
        "\n",
        "# Update this path to match the location of your CSV file\n",
        "# If the Jupyter Notebook and the CSV file are in the same directory, just use the file name\n",
        "csv_file_path = 'DeliveryPoints.csv'\n",
        "\n",
        "# Read CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Your Google Maps API key\n",
        "api_key = \"AIzaSyAJa7jnWhZkkn1EZew1lhOPIwGkejs7D6k\"  # Make sure to replace this with your actual API key\n",
        "\n",
        "# Extract relevant columns from the DataFrame\n",
        "store_id = df['ID No'].tolist()\n",
        "store = df['Store'].tolist()\n",
        "addresses = df['Store Address'].tolist()\n",
        "\n",
        "# Geocode each address and store the coordinates\n",
        "coordinates = []\n",
        "for address in addresses:\n",
        "    lat_lng = get_geocode(address, api_key)\n",
        "    if lat_lng:\n",
        "        coordinates.append(lat_lng)\n",
        "    else:\n",
        "        print(f\"Geocoding API failed for address: {address}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955f6d6b-9962-479a-8059-fad1df35d298",
      "metadata": {
        "id": "955f6d6b-9962-479a-8059-fad1df35d298"
      },
      "source": [
        "**Archiving Store Information and Coordinates to a CSV File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4125b4-d16c-4db9-9176-38964e724003",
      "metadata": {
        "tags": [],
        "id": "2d4125b4-d16c-4db9-9176-38964e724003"
      },
      "outputs": [],
      "source": [
        "# This script takes our prepared lists of store IDs, names, addresses, and their corresponding geographical coordinates\n",
        "# to create a new CSV file. This file organizes our delivery points efficiently, making it easier to visualize and\n",
        "# manage locations for logistical planning.\n",
        "\n",
        "import csv\n",
        "\n",
        "# Assuming you have lists for store IDs, store names, addresses, and coordinates\n",
        "store_id = store_id  # This should be your list of StoreIDs\n",
        "store = store  # List of store names\n",
        "addresses = addresses  # List of addresses\n",
        "coordinates = coordinates  # List of coordinates (latitude, longitude)\n",
        "\n",
        "# Combine the store IDs, store names, addresses, and coordinates into a single list of tuples\n",
        "data_with_store_ids = list(zip(store_id, store, addresses, coordinates))\n",
        "\n",
        "# Define the name of the CSV file to be created\n",
        "csv_file_name = 'DeliveryPoints_coordinates_with_addresses.csv'\n",
        "\n",
        "# Create and write the store IDs, store names, coordinates, and addresses to a CSV file\n",
        "with open(csv_file_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # Write the header\n",
        "    writer.writerow(['Store_ID', 'Store', 'Store Address', 'Latitude', 'Longitude'])\n",
        "    # Write the data\n",
        "    for store_id, store_name, address, (lat, lng) in data_with_store_ids:\n",
        "        writer.writerow([store_id, store_name, address, lat, lng])\n",
        "\n",
        "# Print a confirmation message indicating that the file has been saved\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(f\"File saved: {csv_file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b8d5f0-9726-430d-8253-c55ae6b1170a",
      "metadata": {
        "id": "17b8d5f0-9726-430d-8253-c55ae6b1170a"
      },
      "source": [
        "**Generating Integrated Distance and Duration Matrices for Delivery Points with Google Maps Directions API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56183285-cefd-49e4-9bb3-a7084e63f9b3",
      "metadata": {
        "tags": [],
        "id": "56183285-cefd-49e4-9bb3-a7084e63f9b3"
      },
      "outputs": [],
      "source": [
        "# This script employs Google Maps to calculate the distance and travel time between pairs of delivery points based on\n",
        "# driving routes. It constructs two matrices: one for distances in miles and another for durations in minutes. These\n",
        "# matrices provide a comprehensive view of the travel requirements between locations, crucial for optimizing delivery\n",
        "# routes and scheduling.\n",
        "\n",
        "# List of coordinates (latitude, longitude)\n",
        "coordinates = coordinates\n",
        "\n",
        "# Initialize the Google Maps client with your API key\n",
        "gmaps = googlemaps.Client(key='AIzaSyAJa7jnWhZkkn1EZew1lhOPIwGkejs7D6k') # Make sure to replace this with your actual API key\n",
        "\n",
        "# Determine the number of locations\n",
        "num_locations = len(coordinates)\n",
        "\n",
        "# Initialize matrices for distances and durations\n",
        "distance_matrix = np.zeros((num_locations, num_locations))\n",
        "duration_matrix = np.zeros((num_locations, num_locations))\n",
        "\n",
        "# Calculate distances and durations between each pair of locations\n",
        "for i in range(num_locations):\n",
        "    for j in range(num_locations):\n",
        "        if i == j:\n",
        "            continue  # Skip distance to itself\n",
        "        start = coordinates[i]\n",
        "        end = coordinates[j]\n",
        "        # Format coordinates as \"lat,long\" for the API\n",
        "        start_str = f\"{start[0]},{start[1]}\"  # Corrected order to lat,long\n",
        "        end_str = f\"{end[0]},{end[1]}\"\n",
        "\n",
        "        # Request directions from Google Maps API\n",
        "        directions_result = gmaps.directions(start_str,\n",
        "                                             end_str,\n",
        "                                             mode=\"driving\",\n",
        "                                             departure_time='now',\n",
        "                                             traffic_model='best_guess')\n",
        "\n",
        "        if directions_result:\n",
        "            # Extract distance and duration from the API response\n",
        "            distance = directions_result[0]['legs'][0]['distance']['value'] / 1609.34  # meters to miles\n",
        "            duration = directions_result[0]['legs'][0]['duration']['value'] / 60  # seconds to minutes\n",
        "\n",
        "            # Update the matrices with the calculated values\n",
        "            distance_matrix[i][j] = distance\n",
        "            duration_matrix[i][j] = duration\n",
        "\n",
        "# Convert matrices to DataFrames for readability\n",
        "distance_df = pd.DataFrame(distance_matrix, index=range(num_locations), columns=range(num_locations))\n",
        "duration_df = pd.DataFrame(duration_matrix, index=range(num_locations), columns=range(num_locations))\n",
        "\n",
        "# Print the resulting matrices\n",
        "print(\"Distance Matrix (miles):\")\n",
        "print(distance_df)\n",
        "print(\"\\nDuration Matrix (minutes):\")\n",
        "print(duration_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72dbdcaa-3713-4bac-bff3-75b1436e4e23",
      "metadata": {
        "id": "72dbdcaa-3713-4bac-bff3-75b1436e4e23"
      },
      "source": [
        "**Exporting Store Information and Distance/Duration Matrices to an Excel File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4db446-f3f6-471e-ada3-059fc7b27788",
      "metadata": {
        "tags": [],
        "id": "fa4db446-f3f6-471e-ada3-059fc7b27788"
      },
      "outputs": [],
      "source": [
        "# This script transforms our lists of store details and their distances and durations between each other into structured\n",
        "# tables. It then saves these tables as separate sheets within an Excel workbook, making it easy to manage and visualize\n",
        "# our network of delivery points. Bold formatting is applied to highlight the Store_ID column, ensuring clarity and focus\n",
        "# where it matters most.\n",
        "\n",
        "# Install the xlsxwriter library for writing to Excel files\n",
        "!pip install xlsxwriter\n",
        "\n",
        "# Assuming you have lists for store IDs, store names, addresses, and coordinates\n",
        "store_id = df['ID No'].tolist() # List of store IDs\n",
        "store = store  # List of store names\n",
        "addresses = addresses  # List of addresses\n",
        "coordinates = coordinates  # List of coordinates (latitude, longitude)\n",
        "distance_df = distance_df  # DataFrame containing distance matrix\n",
        "duration_df = duration_df  # DataFrame containing duration matrix\n",
        "\n",
        "# Convert the store information into a DataFrame\n",
        "store_info_df = pd.DataFrame({\n",
        "    'Store_ID': store_id,\n",
        "    'Store': store,\n",
        "    'Store Address': addresses,\n",
        "    'Latitude': [lat for lat, lng in coordinates],\n",
        "    'Longitude': [lng for lat, lng in coordinates]\n",
        "})\n",
        "\n",
        "# Ensure the Store_ID column is correctly set in distance_df and duration_df\n",
        "distance_df['Store_ID'] = store_id  # This will create or overwrite the Store_ID column\n",
        "duration_df['Store_ID'] = store_id  # This will create or overwrite the Store_ID column\n",
        "\n",
        "# Reorder the columns to make Store_ID the first column if it's not already\n",
        "distance_df = distance_df[['Store_ID'] + [col for col in distance_df.columns if col != 'Store_ID']]\n",
        "duration_df = duration_df[['Store_ID'] + [col for col in duration_df.columns if col != 'Store_ID']]\n",
        "\n",
        "# Specify the Excel file name\n",
        "excel_file_name = 'DeliveryPoints_Matrix.xlsx'\n",
        "\n",
        "# Using ExcelWriter to write DataFrames to separate sheets in the same Excel file\n",
        "with pd.ExcelWriter(excel_file_name, engine='xlsxwriter') as writer:\n",
        "    store_info_df.to_excel(writer, sheet_name='Store Information', index=False)\n",
        "    distance_df.to_excel(writer, sheet_name='Distance', index=False)\n",
        "    duration_df.to_excel(writer, sheet_name='Duration', index=False)\n",
        "\n",
        "    # Apply formatting to the Excel file\n",
        "    workbook = writer.book\n",
        "    bold_format = workbook.add_format({'bold': True})\n",
        "\n",
        "    # Apply bold format to the Store_ID column in all sheets\n",
        "    for sheet_name in writer.sheets:\n",
        "        worksheet = writer.sheets[sheet_name]\n",
        "        worksheet.set_column('A:A', None, bold_format)\n",
        "\n",
        "# Print a message indicating that the file has been saved\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(f\"File saved: {excel_file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58b71a0-e963-4a98-a9be-48eb4d2f4292",
      "metadata": {
        "id": "f58b71a0-e963-4a98-a9be-48eb4d2f4292"
      },
      "source": [
        "**Part II: Cluster-Centric Store Delivery Points Segregation with K-Means Clustering Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dfb082b-82c2-4bd5-a515-49efd9742669",
      "metadata": {
        "id": "6dfb082b-82c2-4bd5-a515-49efd9742669"
      },
      "source": [
        "**Strategic Allocation of Store Delivery Points**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d34378-79e6-4458-9cba-f5092b9cbff9",
      "metadata": {
        "tags": [],
        "id": "16d34378-79e6-4458-9cba-f5092b9cbff9"
      },
      "outputs": [],
      "source": [
        "# This script uses the K-Means clustering algorithm to organize delivery points into two groups based on the duration\n",
        "# matrix from our Excel data. Initially, it forms two clusters to minimize travel time. Then, it balances these clusters\n",
        "# to ensure each has a similar number of stores and total travel time is evenly distributed. The aim is to create efficient\n",
        "# and equitable delivery routes, enhancing our logistics planning.\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the Excel file containing the duration matrix\n",
        "file_path = 'DeliveryPoints_Matrix.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "time_matrix_data = pd.read_excel(xls, sheet_name='Duration').drop(\"Store_ID\", axis=1)\n",
        "\n",
        "# Perform initial K-Means clustering to divide the delivery points into 2 clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "kmeans.fit(time_matrix_data)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Define a function to calculate the total time for each cluster\n",
        "def calculate_total_time(matrix, labels):\n",
        "    total_time_per_cluster = [np.sum(matrix[labels == i].sum(axis=1)) for i in range(2)]\n",
        "    return total_time_per_cluster\n",
        "\n",
        "# Define a function to balance clusters by both the number of stores and total time\n",
        "def balance_clusters_equally(matrix, labels, depot_index=0, target_range=(24, 30), max_iterations=1000):\n",
        "    for iteration in range(max_iterations):\n",
        "        total_time_per_cluster = calculate_total_time(matrix, labels)\n",
        "        stores_per_cluster = [sum(labels == i) for i in range(2)]\n",
        "\n",
        "        # Check if the clusters are balanced within the target range and total time difference is acceptable\n",
        "        if all(target_range[0] <= count <= target_range[1] for count in stores_per_cluster) and \\\n",
        "           abs(total_time_per_cluster[0] - total_time_per_cluster[1]) < np.mean(total_time_per_cluster) * 0.1:\n",
        "            break\n",
        "\n",
        "        # Determine which cluster to move a store from\n",
        "        if not all(target_range[0] <= count <= target_range[1] for count in stores_per_cluster):\n",
        "            from_cluster = np.argmax(stores_per_cluster)\n",
        "        else:\n",
        "            from_cluster = np.argmax(total_time_per_cluster)\n",
        "        to_cluster = 1 - from_cluster\n",
        "\n",
        "        # Find the best candidate store to move between clusters\n",
        "        candidates = np.where((labels == from_cluster) & (np.arange(len(labels)) != depot_index))[0]\n",
        "        if len(candidates) > 0:\n",
        "            best_candidate, best_improvement = None, float('inf')\n",
        "            for candidate in candidates:\n",
        "                new_labels = labels.copy()\n",
        "                new_labels[candidate] = to_cluster\n",
        "                new_total_time_per_cluster = calculate_total_time(matrix, new_labels)\n",
        "                new_stores_per_cluster = [sum(new_labels == i) for i in range(2)]\n",
        "                time_diff = abs(new_total_time_per_cluster[0] - new_total_time_per_cluster[1])\n",
        "                store_balance_improvement = abs((stores_per_cluster[0] - stores_per_cluster[1]) - (new_stores_per_cluster[0] - new_stores_per_cluster[1]))\n",
        "                improvement_metric = time_diff + store_balance_improvement\n",
        "                if improvement_metric < best_improvement:\n",
        "                    best_candidate = candidate\n",
        "                    best_improvement = improvement_metric\n",
        "            if best_candidate is not None:\n",
        "                labels[best_candidate] = to_cluster\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Apply the balancing function to the initial cluster labels\n",
        "balanced_labels_equally = balance_clusters_equally(time_matrix_data, cluster_labels.copy())\n",
        "\n",
        "# Retrieve the original store IDs from the \"Duration\" sheet for final assignment\n",
        "store_ids = pd.read_excel(xls, sheet_name='Duration')['Store_ID']\n",
        "final_cluster_assignments = pd.DataFrame({\n",
        "    'Store ID': store_ids,\n",
        "    'Cluster': balanced_labels_equally\n",
        "})\n",
        "\n",
        "# Ensure depot is included in both clusters\n",
        "final_cluster_1_ids = final_cluster_assignments[final_cluster_assignments['Cluster'] == 0]['Store ID'].tolist()\n",
        "final_cluster_2_ids = final_cluster_assignments[final_cluster_assignments['Cluster'] == 1]['Store ID'].tolist()\n",
        "\n",
        "# Check if the depot (ID=0) is in Cluster 1, if not, add it\n",
        "if 0 not in final_cluster_1_ids:\n",
        "    final_cluster_1_ids.append(0)\n",
        "\n",
        "# Check if the depot (ID=0) is in Cluster 2, if not, add it\n",
        "if 0 not in final_cluster_2_ids:\n",
        "    final_cluster_2_ids.append(0)\n",
        "\n",
        "# Sort the IDs in each cluster for better readability\n",
        "final_cluster_1_ids_sorted = sorted(final_cluster_1_ids)\n",
        "final_cluster_2_ids_sorted = sorted(final_cluster_2_ids)\n",
        "\n",
        "# Print the sorted lists of store IDs for each cluster, including the depot\n",
        "print(\"Cluster 1 IDs including depot:\", final_cluster_1_ids_sorted)\n",
        "print(\"Cluster 2 IDs including depot:\", final_cluster_2_ids_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cf2935-d707-4aa0-8f20-3ed92783d387",
      "metadata": {
        "id": "59cf2935-d707-4aa0-8f20-3ed92783d387"
      },
      "source": [
        "**Exporting Route 1 Cluster-Specific Delivery Points Data to Excel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c66d8d4-3d87-4c20-a97c-7bd5189b6231",
      "metadata": {
        "tags": [],
        "id": "2c66d8d4-3d87-4c20-a97c-7bd5189b6231"
      },
      "outputs": [],
      "source": [
        "# This script fine-tunes our treasure trove of delivery points by selecting only those within a specified cluster, thereby\n",
        "# creating a focused dataset. It filters both distance and duration matrices, along with store information, to include only\n",
        "# the relevant delivery points from the first cluster. The refined data is then saved into a new Excel workbook, streamlining\n",
        "# our route planning for more efficient deliveries.\n",
        "\n",
        "# Install the xlsxwriter library for writing to Excel files\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file containing delivery points matrices and store information\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "file_path = 'DeliveryPoints_Matrix.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data sheets from the Excel file into a dictionary\n",
        "data_sheets = {sheet_name: pd.read_excel(xls, sheet_name=sheet_name) for sheet_name in xls.sheet_names}\n",
        "\n",
        "# Define the store IDs for the first cluster\n",
        "cluster1_store_ids = final_cluster_1_ids_sorted\n",
        "\n",
        "# Function to filter the Distance and Duration matrices for a specific cluster\n",
        "def filter_matrices_correctly(matrix_df, cluster_ids):\n",
        "    # Ensure the Store_ID column is in the correct format\n",
        "    matrix_df.set_index('Store_ID', inplace=True)\n",
        "    # Keep only rows and columns corresponding to the cluster IDs\n",
        "    filtered_matrix = matrix_df.loc[cluster_ids, cluster_ids]\n",
        "    # Reset index to bring Store_ID back as a column\n",
        "    filtered_matrix.reset_index(inplace=True)\n",
        "    return filtered_matrix\n",
        "\n",
        "# Apply the filtering function to the Distance and Duration matrices for the first cluster\n",
        "filtered_distance_df = filter_matrices_correctly(data_sheets['Distance'], cluster1_store_ids)\n",
        "filtered_duration_df = filter_matrices_correctly(data_sheets['Duration'], cluster1_store_ids)\n",
        "\n",
        "# Filter the Store Information sheet to include only the stores in the first cluster\n",
        "filtered_store_info_df = data_sheets['Store Information'][data_sheets['Store Information']['Store_ID'].isin(cluster1_store_ids)]\n",
        "\n",
        "# Save the filtered data for the first cluster to a new Excel file\n",
        "output_file_path = 'Route1_DeliveryPoints_Matrix.xlsx'  # Adjust the path if necessary\n",
        "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
        "    filtered_store_info_df.to_excel(writer, sheet_name='Store Information', index=False)\n",
        "    filtered_distance_df.to_excel(writer, sheet_name='Distance', index=False)\n",
        "    filtered_duration_df.to_excel(writer, sheet_name='Duration', index=False)\n",
        "\n",
        "# Print a confirmation message indicating the file has been saved\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(\"Filtered Excel file has been saved:\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2b7231-2950-44a8-a4af-ea7bde70810d",
      "metadata": {
        "id": "df2b7231-2950-44a8-a4af-ea7bde70810d"
      },
      "source": [
        "**Exporting Route 2 Cluster-Specific Delivery Points Data to Excel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0360c129-5b46-4c83-bb2d-917d95260e03",
      "metadata": {
        "id": "0360c129-5b46-4c83-bb2d-917d95260e03"
      },
      "outputs": [],
      "source": [
        "# This script fine-tunes our treasure trove of delivery points by selecting only those within a specified cluster, thereby\n",
        "# creating a focused dataset. It filters both distance and duration matrices, along with store information, to include only\n",
        "# the relevant delivery points from the first cluster. The refined data is then saved into a new Excel workbook, streamlining\n",
        "# our route planning for more efficient deliveries.\n",
        "\n",
        "# Install the xlsxwriter library for writing to Excel files\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file containing delivery points matrices and store information\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "file_path = 'DeliveryPoints_Matrix.xlsx'  # Adjust the path if necessary\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data sheets from the Excel file into a dictionary\n",
        "data_sheets = {sheet_name: pd.read_excel(xls, sheet_name=sheet_name) for sheet_name in xls.sheet_names}\n",
        "\n",
        "# Define the store IDs for the second cluster\n",
        "cluster2_store_ids = final_cluster_2_ids_sorted\n",
        "\n",
        "# Function to filter the Distance and Duration matrices for a specific cluster\n",
        "def filter_matrices_correctly(matrix_df, cluster_ids):\n",
        "    # Ensure the Store_ID column is in the correct format\n",
        "    matrix_df.set_index('Store_ID', inplace=True)\n",
        "    # Keep only rows and columns corresponding to the cluster IDs\n",
        "    filtered_matrix = matrix_df.loc[cluster_ids, cluster_ids]\n",
        "    # Reset index to bring Store_ID back as a column\n",
        "    filtered_matrix.reset_index(inplace=True)\n",
        "    return filtered_matrix\n",
        "\n",
        "# Apply the filtering function to the Distance and Duration matrices for the second cluster\n",
        "filtered_distance_df = filter_matrices_correctly(data_sheets['Distance'], cluster2_store_ids)\n",
        "filtered_duration_df = filter_matrices_correctly(data_sheets['Duration'], cluster2_store_ids)\n",
        "\n",
        "# Filter the Store Information sheet to include only the stores in the second cluster\n",
        "filtered_store_info_df = data_sheets['Store Information'][data_sheets['Store Information']['Store_ID'].isin(cluster2_store_ids)]\n",
        "\n",
        "# Save the filtered data for the second cluster to a new Excel file\n",
        "output_file_path = 'Route2_DeliveryPoints_Matrix.xlsx'  # Adjust the path if necessary\n",
        "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
        "    filtered_store_info_df.to_excel(writer, sheet_name='Store Information', index=False)\n",
        "    filtered_distance_df.to_excel(writer, sheet_name='Distance', index=False)\n",
        "    filtered_duration_df.to_excel(writer, sheet_name='Duration', index=False)\n",
        "\n",
        "# Print a confirmation message indicating the file has been saved\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(\"Filtered Excel file has been saved:\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c3e641-4eec-4798-ae88-61a14d395615",
      "metadata": {
        "id": "d6c3e641-4eec-4798-ae88-61a14d395615"
      },
      "source": [
        "**Part IIIA: Route 1 Delivery Points Optimization using Gurobi Solver**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a11e2221-cc48-4011-bb4e-f83a82f38516",
      "metadata": {
        "id": "a11e2221-cc48-4011-bb4e-f83a82f38516"
      },
      "source": [
        "**Data Preparation for Route 1 Delivery Points Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e8a782-b1fd-4ef1-b635-450b7ae6e501",
      "metadata": {
        "tags": [],
        "id": "87e8a782-b1fd-4ef1-b635-450b7ae6e501"
      },
      "outputs": [],
      "source": [
        "# This script sets the stage for optimizing delivery routes by loading store details, along with distance and duration\n",
        "# matrices, from an Excel workbook. It transforms this information into dictionaries, mapping each pair of origin and\n",
        "# destination to their respective travel times and distances. Additionally, it outlines the process of identifying\n",
        "# specific delivery days, particularly for stores like Costco, and prepares a foundation for calculating loading times\n",
        "# and working hours, crucial for the subsequent steps in route planning.\n",
        "\n",
        "# Adjust the file path below\n",
        "file_path = 'Route1_DeliveryPoints_Matrix.xlsx'  # Update this path\n",
        "\n",
        "from gurobipy import Model, GRB, quicksum\n",
        "\n",
        "# Load the Excel file using the correct sheet names\n",
        "store_details = pd.read_excel(file_path, sheet_name='Store Information')\n",
        "time_matrix_df = pd.read_excel(file_path, sheet_name='Duration')\n",
        "distance_matrix_df = pd.read_excel(file_path, sheet_name='Distance')\n",
        "\n",
        "# Convert the Duration DataFrame into a dictionary where keys are (origin, destination) pairs and values are travel times\n",
        "time_matrix = {\n",
        "    (int(time_matrix_df.iloc[i]['Store_ID']), int(time_matrix_df.columns[j])): time_matrix_df.iloc[i, j]\n",
        "    for i in range(len(time_matrix_df))\n",
        "    for j in range(1, len(time_matrix_df.columns))\n",
        "}\n",
        "\n",
        "# Convert the Distance DataFrame into a dictionary where keys are (origin, destination) pairs and values are travel times\n",
        "distance_matrix = {\n",
        "    (int(distance_matrix_df.iloc[i]['Store_ID']), int(distance_matrix_df.columns[j])): distance_matrix_df.iloc[i, j]\n",
        "    for i in range(len(distance_matrix_df))\n",
        "    for j in range(1, len(distance_matrix_df.columns))\n",
        "}\n",
        "\n",
        "# Process 'store_details' to identify delivery days for each store\n",
        "# Initialize a dictionary to keep track of delivery days for Costco and other stores\n",
        "delivery_days = {}\n",
        "\n",
        "# Define working days, excluding Wednesday and Sunday\n",
        "working_days = ['Monday', 'Tuesday', 'Thursday', 'Friday', 'Saturday']\n",
        "\n",
        "# Prepare a matrix for loading times (assuming 15 minutes for each store)\n",
        "loading_time = 15  # Loading time in minutes\n",
        "working_hours_per_day = 9 * 60\n",
        "\n",
        "# Extract store IDs, including the depot (assumed to be ID 0)\n",
        "stores = sorted(store_details['Store_ID'].unique().tolist())\n",
        "\n",
        "# Identify Costco stores from the 'Store' column\n",
        "costco_stores = store_details[store_details['Store'].str.contains('Costco')]['Store_ID'].unique().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235008f5-bd56-40cc-a28e-c6f4046da775",
      "metadata": {
        "id": "235008f5-bd56-40cc-a28e-c6f4046da775"
      },
      "source": [
        "**Defining Decision Variables, Objective Function, and Constraints (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1139dc2-50fc-47f9-a7b2-06bc5906dbe6",
      "metadata": {
        "tags": [],
        "id": "a1139dc2-50fc-47f9-a7b2-06bc5906dbe6"
      },
      "outputs": [],
      "source": [
        "# In this script, we conjure an optimization model to determine the most efficient delivery routes. By defining binary decision\n",
        "# variables for visits and deliveries, we set our sights on minimizing total travel time. Our primary objective is to pursue\n",
        "# the minimization of total travel time. Constraints ensure each journey begins and ends at the depot, maintains path\n",
        "# continuity, and meets delivery requirements—special attention is given to Costco's daily delivery needs. We also heed\n",
        "# the limits on daily deliveries and working hours to keep our routes practical and manageable. The goal is to weave through\n",
        "# our delivery points with precision, balancing efficiency with operational constraints.\n",
        "\n",
        "# Initialize the model\n",
        "model = Model(\"VehicleRouteOptimization\")\n",
        "\n",
        "# Decision Variables\n",
        "# Create binary variables to represent if a path between two stores is visited on a particular day\n",
        "visit_var = model.addVars(\n",
        "    working_days, [(i, j) for i, j in time_matrix.keys() if i != j],\n",
        "    vtype=GRB.BINARY, name=\"visit\"\n",
        ")\n",
        "\n",
        "# Create binary variables to represent if a store receives a delivery on a particular day\n",
        "delivery_var = model.addVars(\n",
        "    working_days, store_details['Store_ID'].unique(),\n",
        "    vtype=GRB.BINARY, name=\"delivery\"\n",
        ")\n",
        "\n",
        "# Objective Function: Minimize the total travel time across all days and path\n",
        "model.setObjective(\n",
        "    quicksum(visit_var[day, i, j] * time_matrix[(i, j)]\n",
        "             for day in working_days for i, j in time_matrix.keys() if i != j),\n",
        "    GRB.MINIMIZE\n",
        ")\n",
        "\n",
        "# Constraints\n",
        "# Assuming the depot is represented as store 0\n",
        "for day in working_days:\n",
        "    # Ensure each route starts from the depot\n",
        "    model.addConstr(quicksum(visit_var[day, 0, j] for j in stores if j != 0) == 1, f\"StartFromDepot_{day}\")\n",
        "    # Ensure each route ends at the depot\n",
        "    model.addConstr(quicksum(visit_var[day, i, 0] for i in stores if i != 0) == 1, f\"ReturnToDepotLast_{day}\")\n",
        "\n",
        "# Ensure each store is visited exactly once per day if it receives a delivery\n",
        "# i.e. Single exit and entry for each store, ensuring path continuity\n",
        "for day in working_days:\n",
        "    for store in stores[1:]:  # Excluding the depot\n",
        "        model.addConstr(quicksum(visit_var[day, i, store] for i in stores if i != store) >= delivery_var[day, store], f\"MinIncoming_{day}_{store}\")\n",
        "        model.addConstr(quicksum(visit_var[day, store, j] for j in stores if j != store) >= delivery_var[day, store], f\"MinOutgoing_{day}_{store}\")\n",
        "\n",
        "# Ensure Costco stores receive daily deliveries and other stores receive at least 3 deliveries per week\n",
        "for store in stores[1:]:\n",
        "    if store in costco_stores:\n",
        "        for day in working_days:\n",
        "            model.addConstr(delivery_var[day, store] == 1, f\"CostcoDelivery_{day}_{store}\")\n",
        "    else:\n",
        "        model.addConstr(quicksum(delivery_var[day, store] for day in working_days) >= 3, f\"MinDeliveries_{store}\")\n",
        "\n",
        "# Flexible constraint to avoid deliveries after two consecutive delivery days\n",
        "for store in stores:\n",
        "    for i in range(len(working_days) - 2):\n",
        "        day1, day2, day3 = working_days[i], working_days[i + 1], working_days[i + 2]\n",
        "        model.addConstr((delivery_var[day1, store] + delivery_var[day2, store] + (1 - delivery_var[day3, store])) >= 1,\n",
        "                        f\"FlexibleNoConsecutiveDelivery_{store}_{day1}_{day2}_{day3}\")\n",
        "\n",
        "# Limit the maximum number of deliveries per day to ensure logistics feasibility\n",
        "# i.e. the number of deliveries per day to less than 19\n",
        "for day in working_days:\n",
        "    model.addConstr(\n",
        "        quicksum(delivery_var[day, store] for store in stores) <=18,\n",
        "        f\"MaxDeliveriesPerDay_{day}\"\n",
        "    )\n",
        "\n",
        "# Ensure the total working hours per day are not exceeded, accounting for travel and loading times\n",
        "for day in working_days:\n",
        "    model.addConstr(\n",
        "        quicksum((time_matrix[(i, j)] + loading_time) * visit_var[day, i, j] for i in stores for j in stores if i != j) <= working_hours_per_day,\n",
        "        f\"WorkingHours_{day}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d527b014-c141-4488-a7e4-70f8fa2e5c0b",
      "metadata": {
        "id": "d527b014-c141-4488-a7e4-70f8fa2e5c0b"
      },
      "source": [
        "**Executing and Analyzing the Optimization Model Results (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992ea592-e7df-46f3-9dac-5bf9a79e4746",
      "metadata": {
        "tags": [],
        "id": "992ea592-e7df-46f3-9dac-5bf9a79e4746"
      },
      "outputs": [],
      "source": [
        "# This Script solves the optimization model to determine daily routes, then sequences and formats the store visits\n",
        "# for better readability.\n",
        "\n",
        "# Execute the optimization process on the model to find the best routes\n",
        "model.optimize()\n",
        "\n",
        "# Initialize a dictionary to hold the sequence of store visits for each day\n",
        "daily_visits = {day: [] for day in working_days}\n",
        "\n",
        "# Loop through each day to extract and store the sequence of visits from the model's solution\n",
        "for day in working_days:\n",
        "    for i, j in [(i, j) for i in stores for j in stores if i != j]:\n",
        "        # Check if a path between stores i and j is chosen by the model\n",
        "        if visit_var[day, i, j].X > 0.5:  # Using a threshold to determine selection\n",
        "            # Add the stores to the daily visit list if they are part of the route\n",
        "            if i not in daily_visits[day]:\n",
        "                daily_visits[day].append(i)\n",
        "            if j not in daily_visits[day]:\n",
        "                daily_visits[day].append(j)\n",
        "\n",
        "# Define a function to sequence and format the store visits into a readable format\n",
        "def format_sequence(sequence):\n",
        "    # Append the depot as the final destination if not already present\n",
        "    if sequence[-1] != 0:\n",
        "        sequence.append(0)\n",
        "\n",
        "    # Construct a string that narrates the route from store to store\n",
        "    transitions = [f\"store {sequence[i]} to store {sequence[i+1]}\" for i in range(len(sequence) - 1)]\n",
        "    formatted_sequence = \"; \".join(transitions)\n",
        "    return formatted_sequence\n",
        "\n",
        "# Apply the formatting function to the daily visits for presentation\n",
        "for day, stores in daily_visits.items():\n",
        "    formatted_sequence = format_sequence(stores)\n",
        "    print(f\"Day: {day}, Route: {formatted_sequence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5184d94e-ac97-4b00-853d-3bb3ee326d65",
      "metadata": {
        "id": "5184d94e-ac97-4b00-853d-3bb3ee326d65"
      },
      "source": [
        "**Calculating Weekly Total Time for Optimized Delivery Routes (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6ab8a4-c166-4fc3-8187-8151fa4efdcb",
      "metadata": {
        "tags": [],
        "id": "bd6ab8a4-c166-4fc3-8187-8151fa4efdcb"
      },
      "outputs": [],
      "source": [
        "# This Script calculates daily and weekly total delivery times in hours, summarizing the efficiency of the optimized routes.\n",
        "\n",
        "# Initialize the total time counter for the entire week to zero\n",
        "weekly_total_time = 0\n",
        "\n",
        "# Define a function to compute the total operational time for a day's delivery route, including travel and loading times\n",
        "def calculate_total_time_for_day(routes, time_matrix, loading_time):\n",
        "    # Initialize the total time for a single day's route to zero\n",
        "    total_time = 0\n",
        "     # Iterate over each pair of consecutive stores in the route\n",
        "    for i in range(len(routes) - 1):\n",
        "        # Accumulate the travel time between each pair and add loading time\n",
        "        total_time += time_matrix[(routes[i], routes[i+1])] + loading_time\n",
        "    # Subtract the final loading time at the last store since it's not needed\n",
        "    total_time = total_time - 15\n",
        "    # Convert the total time from minutes to hours for better readability\n",
        "    return total_time / 60  # Convert minutes to hours\n",
        "\n",
        "# Loop through each day's route to calculate and display the total time required\n",
        "for day, route in daily_visits.items():\n",
        "    # Calculate the total time for the day using the predefined function\n",
        "    total_time = calculate_total_time_for_day(route, time_matrix, loading_time)\n",
        "    # Print the total time for the day in hours\n",
        "    print(f\"Day: {day}, Total Time: {total_time} hours\")\n",
        "    # Add the day's total time to the weekly total\n",
        "    weekly_total_time += total_time  # Add day's total time to weekly total\n",
        "\n",
        "# Display the total time spent on deliveries for the week\n",
        "print(f\"Total time for the week: {weekly_total_time} hours\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d4a944a-c6a6-40cd-8a7b-e76e337e58e2",
      "metadata": {
        "id": "0d4a944a-c6a6-40cd-8a7b-e76e337e58e2"
      },
      "source": [
        "**Calculating Weekly Total Distance covered for Optimized Delivery Routes (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56641ef9-31ac-4457-ac94-7f8e66744009",
      "metadata": {
        "tags": [],
        "id": "56641ef9-31ac-4457-ac94-7f8e66744009"
      },
      "outputs": [],
      "source": [
        "# This Script computes and presents the total distances traveled each day and for the entire week, offering insights\n",
        "# into route length efficiency.\n",
        "\n",
        "# Initialize the accumulator for the total distance covered in the entire week\n",
        "weekly_total_distance = 0\n",
        "\n",
        "# Define a function to compute the total distance covered for a day's delivery route\n",
        "def calculate_total_distance_for_day(routes, distance_matrix):\n",
        "    total_distance = 0\n",
        "    for i in range(len(routes) - 1):\n",
        "        # Sum the distances between consecutive locations based on the provided distance matrix\n",
        "        total_distance += distance_matrix[(routes[i], routes[i+1])]\n",
        "    return total_distance  # Returns the total distance in the same units as specified in the distance_matrix\n",
        "\n",
        "# Loop through each day's routes to calculate and display the total distance traveled\n",
        "for day, route in daily_visits.items():\n",
        "    total_distance = calculate_total_distance_for_day(route, distance_matrix)\n",
        "    # Display the total distance for the day, assuming miles as the unit of measurement\n",
        "    print(f\"Day: {day}, Total Distance: {total_distance} miles\")\n",
        "    # Increment the weekly total distance by the day's total\n",
        "    weekly_total_distance += total_distance  # Add day's total distance to weekly total\n",
        "\n",
        "# Display the total distance covered over the week\n",
        "print(f\"Total distance for the week: {weekly_total_distance} miles\")  # units depend on how distance is measured in your matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ecad25-8843-4b67-861e-63f3907a322d",
      "metadata": {
        "id": "99ecad25-8843-4b67-861e-63f3907a322d"
      },
      "source": [
        "**Generating and Exporting a Weekly Store Visit Schedule to Excel (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0725eae9-d7f7-4953-a9cb-b3d036b2f52c",
      "metadata": {
        "tags": [],
        "id": "0725eae9-d7f7-4953-a9cb-b3d036b2f52c"
      },
      "outputs": [],
      "source": [
        "# This Script transforms optimized route decisions into a clear weekly schedule, marking store visits, and saves it as\n",
        "# an Excel workbook.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize a DataFrame to structure the weekly delivery schedule for visualization\n",
        "# The columns are all store IDs except 0, and the rows are the working days\n",
        "schedule_df = pd.DataFrame(index=working_days, columns=[store for store in stores if store != 0]).fillna('')  # Start with an empty DataFrame\n",
        "\n",
        "# Iterate over the 'daily_visits' dictionary to populate the DataFrame\n",
        "for day in daily_visits:\n",
        "    for store in daily_visits[day]:\n",
        "        if store != 0:  # Depot is not considered in the schedule\n",
        "            schedule_df.at[day, store] = 'Yes' # Mark 'Yes' for stores visited on each day\n",
        "\n",
        "# Export the populated DataFrame to an Excel file for easy sharing and analysis\n",
        "output_excel_path = 'Route1_Weekly_Store_Visits_Schedule.xlsx'\n",
        "schedule_df.to_excel(output_excel_path)\n",
        "\n",
        "# Print confirmation message indicating successful export\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(f\"Schedule saved to {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770dd401-3306-4c52-831c-550f78a3321a",
      "metadata": {
        "id": "770dd401-3306-4c52-831c-550f78a3321a"
      },
      "source": [
        "**Compiling and Exporting Detailed Daily Journey Metrics to Excel (Route 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377e97b7-bfde-45f9-93f3-d4569d069426",
      "metadata": {
        "tags": [],
        "id": "377e97b7-bfde-45f9-93f3-d4569d069426"
      },
      "outputs": [],
      "source": [
        "# This Script compiles detailed journey segments from optimized routes into a DataFrame and archives\n",
        "# it in an Excel file for review.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Preparing a structured list to capture detailed segments of each journey\n",
        "journey_details = []\n",
        "\n",
        "# Define a fixed loading time for operations at each store\n",
        "loading_time_per_store = 15  # Loading time in minutes for each stop\n",
        "\n",
        "# Loop through the optimized routes for each day to detail journey segments\n",
        "for day in daily_visits:\n",
        "    route = daily_visits[day]  # Retrieve the day's optimized route\n",
        "    for i in range(len(route) - 1):\n",
        "        from_store = route[i]\n",
        "        to_store = route[i + 1]\n",
        "        # Resolve the name of the destination store, or label the depot accordingly\n",
        "        store_name = store_details.loc[store_details['Store_ID'] == to_store, 'Store'].values[0] if to_store != 0 else \"Rudi's Depot\"\n",
        "        travel_time = time_matrix.get((from_store, to_store), 0) # Retrieve the travel time from the matrix\n",
        "        distance = distance_matrix.get((from_store, to_store), 0) # Retrieve the distance from the matrix\n",
        "        # Conditional loading time assignment based on destination\n",
        "        loading_time = 0 if to_store == 0 else loading_time_per_store\n",
        "         # Compute the total time spent in transit including loading times\n",
        "        total_transit_time = travel_time + loading_time\n",
        "\n",
        "        # Compile each journey segment into the details list\n",
        "        journey_details.append([day, from_store, to_store, store_name, distance, travel_time, loading_time, total_transit_time])\n",
        "\n",
        "# Transform the journey details list to a structured DataFrame\n",
        "columns = ['Day', 'From Store_ID', 'To Store_ID', 'Store of To Store_ID', 'Distance Travelled (miles)', 'Time Taken to Travel (min)', 'Loading Time (min)', 'Total Transit Time (min)']\n",
        "journey_df = pd.DataFrame(journey_details, columns=columns)\n",
        "\n",
        "# Export the detailed journey metrics to an Excel file for comprehensive analysis\n",
        "output_excel_path = 'Route1_Daily_Journey_Details.xlsx'\n",
        "journey_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "# Print the successful export of journey metrics\n",
        "print(f\"Journey details saved to {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b23e23-b392-4e8f-98d6-8a5ab3072eb1",
      "metadata": {
        "id": "80b23e23-b392-4e8f-98d6-8a5ab3072eb1"
      },
      "source": [
        "**Part IIIB: Route 2 Delivery Points Optimization using Gurobi Solver**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8435d821-c051-4a76-aebc-f0cbe348eb19",
      "metadata": {
        "tags": [],
        "id": "8435d821-c051-4a76-aebc-f0cbe348eb19"
      },
      "source": [
        "**Data Preparation for Route 2 Delivery Points Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b8737f5-2bcd-4da7-a2de-ee2837a023b6",
      "metadata": {
        "id": "2b8737f5-2bcd-4da7-a2de-ee2837a023b6"
      },
      "outputs": [],
      "source": [
        "# This script sets the stage for optimizing delivery routes by loading store details, along with distance and duration\n",
        "# matrices, from an Excel workbook. It transforms this information into dictionaries, mapping each pair of origin and\n",
        "# destination to their respective travel times and distances. Additionally, it outlines the process of identifying\n",
        "# specific delivery days, particularly for stores like Costco, and prepares a foundation for calculating loading times\n",
        "# and working hours, crucial for the subsequent steps in route planning.\n",
        "\n",
        "# Adjust the file path below\n",
        "file_path = 'Route2_DeliveryPoints_Matrix.xlsx'  # Update this path\n",
        "\n",
        "from gurobipy import Model, GRB, quicksum\n",
        "\n",
        "# Load the Excel file using the correct sheet names\n",
        "store_details = pd.read_excel(file_path, sheet_name='Store Information')\n",
        "time_matrix_df = pd.read_excel(file_path, sheet_name='Duration')\n",
        "distance_matrix_df = pd.read_excel(file_path, sheet_name='Distance')\n",
        "\n",
        "# Convert the Duration DataFrame into a dictionary where keys are (origin, destination) pairs and values are travel times\n",
        "time_matrix = {\n",
        "    (int(time_matrix_df.iloc[i]['Store_ID']), int(time_matrix_df.columns[j])): time_matrix_df.iloc[i, j]\n",
        "    for i in range(len(time_matrix_df))\n",
        "    for j in range(1, len(time_matrix_df.columns))\n",
        "}\n",
        "\n",
        "# Convert the Distance DataFrame into a dictionary where keys are (origin, destination) pairs and values are travel times\n",
        "distance_matrix = {\n",
        "    (int(distance_matrix_df.iloc[i]['Store_ID']), int(distance_matrix_df.columns[j])): distance_matrix_df.iloc[i, j]\n",
        "    for i in range(len(distance_matrix_df))\n",
        "    for j in range(1, len(distance_matrix_df.columns))\n",
        "}\n",
        "\n",
        "# Process 'store_details' to identify delivery days for each store\n",
        "# Initialize a dictionary to keep track of delivery days for Costco and other stores\n",
        "delivery_days = {}\n",
        "\n",
        "# Define working days, excluding Wednesday and Sunday\n",
        "working_days = ['Monday', 'Tuesday', 'Thursday', 'Friday', 'Saturday']\n",
        "\n",
        "# Prepare a matrix for loading times (assuming 15 minutes for each store)\n",
        "loading_time = 15  # Loading time in minutes\n",
        "working_hours_per_day = 9 * 60\n",
        "\n",
        "# Extract store IDs, including the depot (assumed to be ID 0)\n",
        "stores = sorted(store_details['Store_ID'].unique().tolist())\n",
        "\n",
        "# Identify Costco stores from the 'Store' column\n",
        "costco_stores = store_details[store_details['Store'].str.contains('Costco')]['Store_ID'].unique().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab74cb89-d638-4fdb-a8e3-b4af7a1cdefd",
      "metadata": {
        "id": "ab74cb89-d638-4fdb-a8e3-b4af7a1cdefd"
      },
      "source": [
        "**Defining Decision Variables, Objective Function, and Constraints (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b0da39-6123-497a-8568-ef93f19cc8b2",
      "metadata": {
        "id": "18b0da39-6123-497a-8568-ef93f19cc8b2"
      },
      "outputs": [],
      "source": [
        "# In this script, we conjure an optimization model to determine the most efficient delivery routes. By defining binary decision\n",
        "# variables for visits and deliveries, we set our sights on minimizing total travel time. Our primary objective is to pursue\n",
        "# the minimization of total travel time. Constraints ensure each journey begins and ends at the depot, maintains path\n",
        "# continuity, and meets delivery requirements—special attention is given to Costco's daily delivery needs. We also heed\n",
        "# the limits on daily deliveries and working hours to keep our routes practical and manageable. The goal is to weave through\n",
        "# our delivery points with precision, balancing efficiency with operational constraints.\n",
        "\n",
        "# Initialize the model\n",
        "model = Model(\"VehicleRouteOptimization\")\n",
        "\n",
        "# Decision Variables\n",
        "# Create binary variables to represent if a path between two stores is visited on a particular day\n",
        "visit_var = model.addVars(\n",
        "    working_days, [(i, j) for i, j in time_matrix.keys() if i != j],\n",
        "    vtype=GRB.BINARY, name=\"visit\"\n",
        ")\n",
        "\n",
        "# Create binary variables to represent if a store receives a delivery on a particular day\n",
        "delivery_var = model.addVars(\n",
        "    working_days, store_details['Store_ID'].unique(),\n",
        "    vtype=GRB.BINARY, name=\"delivery\"\n",
        ")\n",
        "\n",
        "# Objective Function: Minimize the total travel time across all days and path\n",
        "model.setObjective(\n",
        "    quicksum(visit_var[day, i, j] * time_matrix[(i, j)]\n",
        "             for day in working_days for i, j in time_matrix.keys() if i != j),\n",
        "    GRB.MINIMIZE\n",
        ")\n",
        "\n",
        "# Constraints\n",
        "# Assuming the depot is represented as store 0\n",
        "for day in working_days:\n",
        "    # Ensure each route starts from the depot\n",
        "    model.addConstr(quicksum(visit_var[day, 0, j] for j in stores if j != 0) == 1, f\"StartFromDepot_{day}\")\n",
        "    # Ensure each route ends at the depot\n",
        "    model.addConstr(quicksum(visit_var[day, i, 0] for i in stores if i != 0) == 1, f\"ReturnToDepotLast_{day}\")\n",
        "\n",
        "# Ensure each store is visited exactly once per day if it receives a delivery\n",
        "# i.e. Single exit and entry for each store, ensuring path continuity\n",
        "for day in working_days:\n",
        "    for store in stores[1:]:  # Excluding the depot\n",
        "        model.addConstr(quicksum(visit_var[day, i, store] for i in stores if i != store) >= delivery_var[day, store], f\"MinIncoming_{day}_{store}\")\n",
        "        model.addConstr(quicksum(visit_var[day, store, j] for j in stores if j != store) >= delivery_var[day, store], f\"MinOutgoing_{day}_{store}\")\n",
        "\n",
        "# Ensure Costco stores receive daily deliveries and other stores receive at least 3 deliveries per week\n",
        "for store in stores[1:]:\n",
        "    if store in costco_stores:\n",
        "        for day in working_days:\n",
        "            model.addConstr(delivery_var[day, store] == 1, f\"CostcoDelivery_{day}_{store}\")\n",
        "    else:\n",
        "        model.addConstr(quicksum(delivery_var[day, store] for day in working_days) >= 3, f\"MinDeliveries_{store}\")\n",
        "\n",
        "# Flexible constraint to avoid deliveries after two consecutive delivery days\n",
        "for store in stores:\n",
        "    for i in range(len(working_days) - 2):\n",
        "        day1, day2, day3 = working_days[i], working_days[i + 1], working_days[i + 2]\n",
        "        model.addConstr((delivery_var[day1, store] + delivery_var[day2, store] + (1 - delivery_var[day3, store])) >= 1,\n",
        "                        f\"FlexibleNoConsecutiveDelivery_{store}_{day1}_{day2}_{day3}\")\n",
        "\n",
        "# Limit the maximum number of deliveries per day to ensure logistics feasibility\n",
        "# i.e. the number of deliveries per day to less than 17\n",
        "for day in working_days:\n",
        "    model.addConstr(\n",
        "        quicksum(delivery_var[day, store] for store in stores) <=16,\n",
        "        f\"MaxDeliveriesPerDay_{day}\"\n",
        "    )\n",
        "\n",
        "# Ensure the total working hours per day are not exceeded, accounting for travel and loading times\n",
        "for day in working_days:\n",
        "    model.addConstr(\n",
        "        quicksum((time_matrix[(i, j)] + loading_time) * visit_var[day, i, j] for i in stores for j in stores if i != j) <= working_hours_per_day,\n",
        "        f\"WorkingHours_{day}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f986e882-ce2c-4c3e-bd32-337a9681b3f5",
      "metadata": {
        "id": "f986e882-ce2c-4c3e-bd32-337a9681b3f5"
      },
      "source": [
        "**Executing and Analyzing the Optimization Model Results (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e7d5115-3124-49e5-ad21-007b00f1b9ec",
      "metadata": {
        "id": "2e7d5115-3124-49e5-ad21-007b00f1b9ec"
      },
      "outputs": [],
      "source": [
        "# This Script solves the optimization model to determine daily routes, then sequences and formats the store visits\n",
        "# for better readability.\n",
        "\n",
        "# Execute the optimization process on the model to find the best routes\n",
        "model.optimize()\n",
        "\n",
        "# Initialize a dictionary to hold the sequence of store visits for each day\n",
        "daily_visits = {day: [] for day in working_days}\n",
        "\n",
        "# Loop through each day to extract and store the sequence of visits from the model's solution\n",
        "for day in working_days:\n",
        "    for i, j in [(i, j) for i in stores for j in stores if i != j]:\n",
        "        # Check if a path between stores i and j is chosen by the model\n",
        "        if visit_var[day, i, j].X > 0.5:  # Using a threshold to determine selection\n",
        "            # Add the stores to the daily visit list if they are part of the route\n",
        "            if i not in daily_visits[day]:\n",
        "                daily_visits[day].append(i)\n",
        "            if j not in daily_visits[day]:\n",
        "                daily_visits[day].append(j)\n",
        "\n",
        "# Define a function to sequence and format the store visits into a readable format\n",
        "def format_sequence(sequence):\n",
        "    # Append the depot as the final destination if not already present\n",
        "    if sequence[-1] != 0:\n",
        "        sequence.append(0)\n",
        "\n",
        "    # Construct a string that narrates the route from store to store\n",
        "    transitions = [f\"store {sequence[i]} to store {sequence[i+1]}\" for i in range(len(sequence) - 1)]\n",
        "    formatted_sequence = \"; \".join(transitions)\n",
        "    return formatted_sequence\n",
        "\n",
        "# Apply the formatting function to the daily visits for presentation\n",
        "for day, stores in daily_visits.items():\n",
        "    formatted_sequence = format_sequence(stores)\n",
        "    print(f\"Day: {day}, Route: {formatted_sequence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac8b6ab0-6e86-4478-8cde-2b9e36e23f48",
      "metadata": {
        "id": "ac8b6ab0-6e86-4478-8cde-2b9e36e23f48"
      },
      "source": [
        "**Calculating Weekly Total Time for Optimized Delivery Routes (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0815aa56-a476-4d59-bdfc-ee68a5444f9b",
      "metadata": {
        "id": "0815aa56-a476-4d59-bdfc-ee68a5444f9b"
      },
      "outputs": [],
      "source": [
        "# This Script calculates daily and weekly total delivery times in hours, summarizing the efficiency of the optimized routes.\n",
        "\n",
        "# Initialize the total time counter for the entire week to zero\n",
        "weekly_total_time = 0\n",
        "\n",
        "# Define a function to compute the total operational time for a day's delivery route, including travel and loading times\n",
        "def calculate_total_time_for_day(routes, time_matrix, loading_time):\n",
        "    # Initialize the total time for a single day's route to zero\n",
        "    total_time = 0\n",
        "     # Iterate over each pair of consecutive stores in the route\n",
        "    for i in range(len(routes) - 1):\n",
        "        # Accumulate the travel time between each pair and add loading time\n",
        "        total_time += time_matrix[(routes[i], routes[i+1])] + loading_time\n",
        "    # Subtract the final loading time at the last store since it's not needed\n",
        "    total_time = total_time - 15\n",
        "    # Convert the total time from minutes to hours for better readability\n",
        "    return total_time / 60  # Convert minutes to hours\n",
        "\n",
        "# Loop through each day's route to calculate and display the total time required\n",
        "for day, route in daily_visits.items():\n",
        "    # Calculate the total time for the day using the predefined function\n",
        "    total_time = calculate_total_time_for_day(route, time_matrix, loading_time)\n",
        "    # Print the total time for the day in hours\n",
        "    print(f\"Day: {day}, Total Time: {total_time} hours\")\n",
        "    # Add the day's total time to the weekly total\n",
        "    weekly_total_time += total_time  # Add day's total time to weekly total\n",
        "\n",
        "# Display the total time spent on deliveries for the week\n",
        "print(f\"Total time for the week: {weekly_total_time} hours\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba00bf3-ab17-42e9-a486-827b8aa4af96",
      "metadata": {
        "id": "0ba00bf3-ab17-42e9-a486-827b8aa4af96"
      },
      "source": [
        "**Calculating Weekly Total Distance covered for Optimized Delivery Routes (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "548ac4c2-8e6c-428b-8b4b-748ea89c6d32",
      "metadata": {
        "id": "548ac4c2-8e6c-428b-8b4b-748ea89c6d32"
      },
      "outputs": [],
      "source": [
        "# This Script computes and presents the total distances traveled each day and for the entire week, offering insights\n",
        "# into route length efficiency.\n",
        "\n",
        "# Initialize the accumulator for the total distance covered in the entire week\n",
        "weekly_total_distance = 0\n",
        "\n",
        "# Define a function to compute the total distance covered for a day's delivery route\n",
        "def calculate_total_distance_for_day(routes, distance_matrix):\n",
        "    total_distance = 0\n",
        "    for i in range(len(routes) - 1):\n",
        "        # Sum the distances between consecutive locations based on the provided distance matrix\n",
        "        total_distance += distance_matrix[(routes[i], routes[i+1])]\n",
        "    return total_distance  # Returns the total distance in the same units as specified in the distance_matrix\n",
        "\n",
        "# Loop through each day's routes to calculate and display the total distance traveled\n",
        "for day, route in daily_visits.items():\n",
        "    total_distance = calculate_total_distance_for_day(route, distance_matrix)\n",
        "    # Display the total distance for the day, assuming miles as the unit of measurement\n",
        "    print(f\"Day: {day}, Total Distance: {total_distance} miles\")\n",
        "    # Increment the weekly total distance by the day's total\n",
        "    weekly_total_distance += total_distance  # Add day's total distance to weekly total\n",
        "\n",
        "# Display the total distance covered over the week\n",
        "print(f\"Total distance for the week: {weekly_total_distance} miles\")  # units depend on how distance is measured in your matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6a0c258-1e38-416f-a97e-619f72fb7c59",
      "metadata": {
        "id": "d6a0c258-1e38-416f-a97e-619f72fb7c59"
      },
      "source": [
        "**Generating and Exporting a Weekly Store Visit Schedule to Excel (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53339d16-1b05-464c-bd87-cc7b6c25500b",
      "metadata": {
        "id": "53339d16-1b05-464c-bd87-cc7b6c25500b"
      },
      "outputs": [],
      "source": [
        "# This Script transforms optimized route decisions into a clear weekly schedule, marking store visits, and saves it as\n",
        "# an Excel workbook.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize a DataFrame to structure the weekly delivery schedule for visualization\n",
        "# The columns are all store IDs except 0, and the rows are the working days\n",
        "schedule_df = pd.DataFrame(index=working_days, columns=[store for store in stores if store != 0]).fillna('')  # Start with an empty DataFrame\n",
        "\n",
        "# Iterate over the 'daily_visits' dictionary to populate the DataFrame\n",
        "for day in daily_visits:\n",
        "    for store in daily_visits[day]:\n",
        "        if store != 0:  # Depot is not considered in the schedule\n",
        "            schedule_df.at[day, store] = 'Yes' # Mark 'Yes' for stores visited on each day\n",
        "\n",
        "# Export the populated DataFrame to an Excel file for easy sharing and analysis\n",
        "output_excel_path = 'Route2_Weekly_Store_Visits_Schedule.xlsx'\n",
        "schedule_df.to_excel(output_excel_path)\n",
        "\n",
        "# Print confirmation message indicating successful export\n",
        "# In a Jupyter Notebook, files are saved to the notebook's server file system\n",
        "print(f\"Schedule saved to {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06dd5f7-802c-43f2-bc11-47a2d276813c",
      "metadata": {
        "id": "c06dd5f7-802c-43f2-bc11-47a2d276813c"
      },
      "source": [
        "**Compiling and Exporting Detailed Daily Journey Metrics to Excel (Route 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ba75ca6-3cc6-4b69-a270-e360174fc799",
      "metadata": {
        "id": "5ba75ca6-3cc6-4b69-a270-e360174fc799"
      },
      "outputs": [],
      "source": [
        "# This Script compiles detailed journey segments from optimized routes into a DataFrame and archives\n",
        "# it in an Excel file for review.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Preparing a structured list to capture detailed segments of each journey\n",
        "journey_details = []\n",
        "\n",
        "# Define a fixed loading time for operations at each store\n",
        "loading_time_per_store = 15  # Loading time in minutes for each stop\n",
        "\n",
        "# Loop through the optimized routes for each day to detail journey segments\n",
        "for day in daily_visits:\n",
        "    route = daily_visits[day]  # Retrieve the day's optimized route\n",
        "    for i in range(len(route) - 1):\n",
        "        from_store = route[i]\n",
        "        to_store = route[i + 1]\n",
        "        # Resolve the name of the destination store, or label the depot accordingly\n",
        "        store_name = store_details.loc[store_details['Store_ID'] == to_store, 'Store'].values[0] if to_store != 0 else \"Rudi's Depot\"\n",
        "        travel_time = time_matrix.get((from_store, to_store), 0) # Retrieve the travel time from the matrix\n",
        "        distance = distance_matrix.get((from_store, to_store), 0) # Retrieve the distance from the matrix\n",
        "        # Conditional loading time assignment based on destination\n",
        "        loading_time = 0 if to_store == 0 else loading_time_per_store\n",
        "         # Compute the total time spent in transit including loading times\n",
        "        total_transit_time = travel_time + loading_time\n",
        "\n",
        "        # Compile each journey segment into the details list\n",
        "        journey_details.append([day, from_store, to_store, store_name, distance, travel_time, loading_time, total_transit_time])\n",
        "\n",
        "# Transform the journey details list to a structured DataFrame\n",
        "columns = ['Day', 'From Store_ID', 'To Store_ID', 'Store of To Store_ID', 'Distance Travelled (miles)', 'Time Taken to Travel (min)', 'Loading Time (min)', 'Total Transit Time (min)']\n",
        "journey_df = pd.DataFrame(journey_details, columns=columns)\n",
        "\n",
        "# Export the detailed journey metrics to an Excel file for comprehensive analysis\n",
        "output_excel_path = 'Route2_Daily_Journey_Details.xlsx'\n",
        "journey_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "# Print the successful export of journey metrics\n",
        "print(f\"Journey details saved to {output_excel_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}